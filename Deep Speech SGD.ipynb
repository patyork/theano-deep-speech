{
 "metadata": {
  "name": "",
  "signature": "sha256:1d8a54be3a7c321c55a5b4594a08dc506b5a3427f0e4b21204c8664ccffb97ca"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "__author__ = 'pat'\n",
      "import numpy as np\n",
      "import math\n",
      "import time\n",
      "from itertools import groupby\n",
      "import matplotlib.pyplot as plt\n",
      "from matplotlib.lines import Line2D\n",
      "import cPickle as pickle\n",
      "import theano\n",
      "\n",
      "import brnn_stacked as nn\n",
      "\n",
      "\n",
      "def str_to_seq(str):\n",
      "    seq = []\n",
      "    for c in str:\n",
      "        val = ord(c)\n",
      "        if val==32:\n",
      "            val = 26\n",
      "        elif val==39:\n",
      "            val=27\n",
      "        elif val==45:\n",
      "            val=28\n",
      "        else:\n",
      "            val-=97\n",
      "        seq.append(val)\n",
      "    return seq\n",
      "    \n",
      "\n",
      "def seq_to_str(seq):\n",
      "    str = ''\n",
      "    for elem in seq:\n",
      "        if elem==26:\n",
      "            str += ' '\n",
      "        elif elem==27:\n",
      "            str += '\\''\n",
      "        elif elem==28:\n",
      "            str += '-'\n",
      "        elif elem==29:\n",
      "            pass\n",
      "        else:\n",
      "            str += chr(elem+97)\n",
      "    return str\n",
      "    \n",
      "\n",
      "# Remove consecutive symbols and blanks\n",
      "def F(pi, blank):\n",
      "    return [a for a in [key for key, _ in groupby(pi)] if a != blank]\n",
      "    \n",
      "\n",
      "# Insert blanks between unique symbols, and at the beginning and end\n",
      "def make_l_prime(l, blank):\n",
      "    result = [blank] * (len(l) * 2 + 1)\n",
      "    result[1::2] = l\n",
      "    return result\n",
      "    \n",
      "    \n",
      "def log_it(f, epoch=None, error=None, etime=None, samples=None, nan=False, etc=None):\n",
      "    s5 = '&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'\n",
      "    if epoch is not None:\n",
      "        message = time.strftime('%H:%M:%S') + '\\tEpoch: ' + str(epoch) + '\\tAvg. Error: ' + str(error / samples) + '\\tin ' + str(etime) + 's\\t' +str(samples) + ' samples\\tSamples/sec: ' + str(samples/etime) + '\\tApprox. Speed: ' + str(samples * 5 / etime) + 'x real-time'\n",
      "        print '\\n', message, '\\n'\n",
      "        f.write(message.replace('\\t', s5) + '<br />')\n",
      "    elif nan:\n",
      "        print time.strftime('%H:%M:%S') + '\\n========\\nHIT NAN=======\\nInvalidating Epoch\\n===========\\n'\n",
      "        f.write('<br />' + time.strftime('%H:%M:%S') + '\\n========\\nHIT NAN=======\\nInvalidating Epoch\\n===========\\n\\n<br />')\n",
      "        \n",
      "    else:\n",
      "        print etc\n",
      "        f.write(time.strftime('%H:%M:%S') +s5+ etc.replace('\\n', '<br />').replace('\\t', s5) + '<br />')\n",
      "\n",
      "\n",
      "alphabet = np.arange(29) #[a,....,z, space, ', -]\n",
      "\n",
      "\n",
      "# Load samples\n",
      "f = open('win3_l35.pkl', 'rb')\n",
      "samples = pickle.load(f)\n",
      "f.close()\n",
      "\n",
      "samples = samples[:1000]\n",
      "\n",
      "samples_sorted = sorted(samples, key=lambda s: len(s[0]))\n",
      "lens = [len(s[0]) for s in samples_sorted]\n",
      "lp_lens = [key for key, _ in groupby(lens)]\n",
      "\n",
      "batch_dict = {}\n",
      "for length in lp_lens:\n",
      "    # Get samples of length\n",
      "    sample_of_len = []\n",
      "    label_of_len = []\n",
      "    for s in samples:\n",
      "        if len(s[0]) == length:\n",
      "            sample_of_len.append(np.asarray(s[1], dtype=theano.config.floatX))\n",
      "            label_of_len.append(np.asarray(s[0], dtype='int32'))\n",
      "\n",
      "    pad_to = np.max([s.shape[0] for s in sample_of_len])\n",
      "    padded = []\n",
      "    for s in sample_of_len:\n",
      "\n",
      "        pad = np.zeros((pad_to-s.shape[0], s.shape[1]))\n",
      "        padded.append( np.concatenate((s, pad), axis=0))\n",
      "\n",
      "    batch_dict[length] = (np.asarray(label_of_len, dtype='int32'), np.asarray(padded, dtype=theano.config.floatX))\n",
      "\n",
      "\n",
      "visual_samples_y = batch_dict[lp_lens[5]][0][0:5]\n",
      "visual_samples_x = batch_dict[lp_lens[5]][1][0:5]\n",
      "\n",
      "print visual_samples_y.shape, visual_samples_x.shape\n",
      "print [seq_to_str(s) for s in visual_samples_y]\n",
      "\n",
      "\n",
      "# PARAMETERS\n",
      "epoch_size = 100        # mini-batches per epoch (model is stored at the end of this many mini-batches)\n",
      "batch_size = 5        # mini-batch size\n",
      "\n",
      "# HYPER-PARAMETERS\n",
      "learning_rate = .01\n",
      "momentum_coefficient = .25\n",
      "\n",
      "# Automatically Generated Parameters\n",
      "alphabet_len = len(alphabet)\n",
      "input_dim = visual_samples_x.shape[2]\n",
      "\n",
      "\n",
      "net = nn.Network()\n",
      "rng = np.random.RandomState(int(time.time()))\n",
      "\n",
      "\n",
      "duration = time.time()\n",
      "network = net.create_network(input_dim, alphabet_len+1, batch_size=batch_size, learning_rate=learning_rate, momentum=momentum_coefficient)\n",
      "print 'Network compiled in %.3fs' % (time.time() - duration)\n",
      "\n",
      "\n",
      "for i in np.arange(10):\n",
      "    duration = time.time()\n",
      "    new_shape = (visual_samples_x.shape[0]*visual_samples_x.shape[1], input_dim)\n",
      "    output = network.trainer(visual_samples_x.reshape(new_shape), visual_samples_y, 0.1)[0]\n",
      "\n",
      "    print output.shape, output, time.time() - duration\n",
      "\n",
      "\n",
      "raw_input(\"asdf\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# create network\n",
      "try:\n",
      "    last_good = -1\n",
      "    restart = False\n",
      "    #log_file = file('/var/www/html/status.html', 'a')\n",
      "    log_file = file('status.html', 'a')\n",
      "    duration = time.time()\n",
      "    if last_good == -1:\n",
      "        network = net.create_network(560, len(alphabet)+1, .0005, .75)        #x3 for the window\n",
      "        log_it(log_file, etc='created Network - num samples:' + str(len(samples)) + '\\tDuration: ' + str(time.time()-duration))\n",
      "    else:\n",
      "        picklePath = 'saved_models_batch/' + str(last_good) + '.pkl'\n",
      "        print 'loading from', picklePath\n",
      "        network = net.load_network(picklePath, 560, len(alphabet)+1, .0005, .75)        #x3 for the window\n",
      "        log_it(log_file, etc='loaded Network - num samples:' + str(len(samples)) + '\\tDuration: ' + str(time.time()-duration))\n",
      "    log_file.close()\n",
      "\n",
      "    if last_good == -1:\n",
      "        error_avg_epoch = 0.0\n",
      "        duration = time.time()\n",
      "\n",
      "        # For each bucket of samples\n",
      "        for length in lp_lens:\n",
      "\n",
      "            sequence_length = length\n",
      "\n",
      "            for i in np.arange(0, math.ceil(sequence_length/batch_size)):\n",
      "                duration2 = time.time()\n",
      "\n",
      "                temp_model = network.get_parameters()\n",
      "\n",
      "                num_samples_in_selected = batch_dict[sequence_length][1].shape[0] - (i*batch_size)    # get the number of available samples in the bucket\n",
      "\n",
      "                if num_samples_in_selected < batch_size:\n",
      "                    minibatch_start = (i*batch_size)\n",
      "                    minibatch_end = (i*batch_size) + num_samples_in_selected\n",
      "                else:\n",
      "                    minibatch_start = i * batch_size\n",
      "                    minibatch_end = minibatch_start + batch_size\n",
      "                    \n",
      "                print 'Shape:', batch_dict[sequence_length][1][minibatch_start:minibatch_end, :, :].shape\n",
      "\n",
      "                cost, _ = network.trainer(batch_dict[sequence_length][1][minibatch_start:minibatch_end, :, :], batch_dict[sequence_length][0][minibatch_start:minibatch_end, :])\n",
      "\n",
      "                if math.isnan(cost) or math.isinf(cost):\n",
      "                    restart = True\n",
      "                    network.set_parameters(temp_model)\n",
      "                    #raw_input(\"Hit NAN on sequential first-round input!! Very bad...\")\n",
      "                    print(\"Hit NAN on sequential first-round input!! Very bad...\")\n",
      "                    break\n",
      "\n",
      "                error_avg_epoch += cost\n",
      "                print '\\t', cost, minibatch_end-minibatch_start, time.time()-duration2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    # Start a new Epoch\n",
      "    for epoch in np.arange(last_good+1, 100000):\n",
      "\n",
      "        error_avg_epoch = 0.0\n",
      "        duration = time.time()\n",
      "\n",
      "        # For each desired mini-batch\n",
      "        for minibatch in np.arange(epoch_size):\n",
      "            temp_model = network.get_parameters()\n",
      "            \n",
      "            duration2 = time.time()\n",
      "\n",
      "            sequence_length_index = rng.randint(0, len(lp_lens))                                # randomly select a bucket of samples to create a mini-batch from\n",
      "            sequence_length = lp_lens[sequence_length_index]\n",
      "\n",
      "            num_samples_in_selected = batch_dict[sequence_length][1].shape[0]    # get the number of available samples in the bucket\n",
      "            \n",
      "            if False: minibatch_start = 0; minibatch_end = batch_size\n",
      "            elif num_samples_in_selected < batch_size:\n",
      "                minibatch_start = 0\n",
      "                minibatch_end = num_samples_in_selected\n",
      "            else:\n",
      "                minibatch_start = rng.randint(0, len(lp_lens))\n",
      "                minibatch_end = minibatch_start + batch_size\n",
      "\n",
      "            cost, _ = network.trainer(batch_dict[sequence_length][1][minibatch_start:minibatch_end, :, :], batch_dict[sequence_length][0][minibatch_start:minibatch_end, :])\n",
      "\n",
      "            if math.isnan(cost) or math.isinf(cost):\n",
      "                #restart = True\n",
      "                #break\n",
      "                network.set_parameters(temp_model)\n",
      "                print \"hit nan - undoing batch\"\n",
      "\n",
      "            error_avg_epoch += cost\n",
      "            print '\\t', cost, minibatch_end-minibatch_start, time.time()-duration2\n",
      "\n",
      "\n",
      "        log_file = file('status.html', 'a') #file('/var/www/html/status.html', 'a')\n",
      "        if not restart:\n",
      "\n",
      "            print 'Avg. Error:', error_avg_epoch, ' || over', batch_dict[sequence_length][1].shape, '\\tsamples\\t | in %.3fs' % (time.time() - duration)\n",
      "            \n",
      "            pred = network.tester(visual_samples_x)[0]\n",
      "            for i in np.arange(2):\n",
      "                log_it(log_file, etc='\\t' + seq_to_str(visual_sample_y[i]) + ' || ' + seq_to_str([np.argmax(x) for x in pred[i]]))\n",
      "\n",
      "            if epoch % 10: #epoch_size:\n",
      "                dumpPath = 'saved_models_batch/' + str(epoch) + '.pkl'\n",
      "                print 'Saving to: ', dumpPath\n",
      "                net.dump_network(dumpPath)\n",
      "\n",
      "                last_good = epoch\n",
      "\n",
      "        else:\n",
      "            log_it(log_file, nan=True)\n",
      "            restart = False\n",
      "\n",
      "            duration = time.time()\n",
      "            picklePath = 'saved_models_batch/' + str(last_good) + '.pkl'\n",
      "            print 'loading from', picklePath\n",
      "            network = net.load_network(picklePath, 560, len(alphabet)+1, .0005, .75)        #x3 for the window\n",
      "            log_it(log_file, etc='loaded Network - num samples:' + str(len(samples)) + '\\tDuration: ' + str(time.time()-duration))\n",
      "        log_file.close()\n",
      "\n",
      "\n",
      "except KeyboardInterrupt:\n",
      "    pass\n",
      "\n",
      "# shuffle lp_lens\n",
      "\n",
      "# take lp_lens[0] as length\n",
      "\n",
      "    # random from [0, batch_dict[length]-batch_size]\n",
      "\n",
      "    # batch train on the random slice\n",
      "\n",
      "    # every Xth training batch, save model, shuffle\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}